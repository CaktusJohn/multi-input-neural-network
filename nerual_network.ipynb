{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be5ee9a4",
   "metadata": {},
   "source": [
    "Загрузка данных. Размерность (batch_size, max_len, num_features) - (количество таблиц, строк, столбцов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525443ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d062a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.load(\"X.npy\")\n",
    "y = np.load(\"y.npy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02faf2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False\n",
      "False False\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(X).any(), np.isnan(y).any()) # булев массив, хотябы 1 true\n",
    "print(np.isinf(X).any(), np.isinf(y).any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98c17613",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.nan_to_num(X)\n",
    "y = np.nan_to_num(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "775792eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X min/max: -17531.0 312972.0\n",
      "y min/max: 0.0 127.301369863\n"
     ]
    }
   ],
   "source": [
    "print(\"X min/max:\", X.min(), X.max())\n",
    "print(\"y min/max:\", y.min(), y.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c450478d",
   "metadata": {},
   "source": [
    "Есть разброс значений, а нейронки к ним чувствительны, требуется предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad055040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# отделяем тестовую выборку (20% данных)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# из оставшихся данных выделяем валидационную выборку (25% от оставшихся = 20% от всех данных)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d94ea1",
   "metadata": {},
   "source": [
    "Масштабирование признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e4ca837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# масштабируем только по обучающей выборке, чтобы не подглядывать в валидацию/тест\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# преобразуем каждую части (train/val/test) отдельно по форме (N, T, F) -> (N*T, F)\n",
    "X_train_reshaped = X_train.reshape(-1, X_train.shape[-1])\n",
    "X_val_reshaped = X_val.reshape(-1, X_val.shape[-1])\n",
    "X_test_reshaped = X_test.reshape(-1, X_test.shape[-1])\n",
    "\n",
    "# fit только на тренировочных данных\n",
    "scaler.fit(X_train_reshaped)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train_reshaped).reshape(X_train.shape)\n",
    "X_val_scaled = scaler.transform(X_val_reshaped).reshape(X_val.shape)\n",
    "X_test_scaled = scaler.transform(X_test_reshaped).reshape(X_test.shape)\n",
    "\n",
    "X_train = X_train_scaled\n",
    "X_val = X_val_scaled\n",
    "X_test = X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a9d5f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset): # свой класс датасета, наследуясь от Dataset\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32) #тензор из нумпай массива\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "val_dataset = CustomDataset(X_val, y_val)\n",
    "test_dataset = CustomDataset(X_test, y_test)\n",
    "# shuffle перемешивает порядок на каждой эпохе\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True) #возвращает батчи в обучении\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a78cbfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn #нейросетевые слои (например, Linear, LSTM, Conv2d)\n",
    "# и базовый класс nn.Module для создания собственных моделей\n",
    "\n",
    "#  Модель (many-to-one). Наследуем от nn и можем использовать встроенные возможности фреймворка \n",
    "# (автоматическое вычисление градиентов, перенос на GPU, сохранение модели и т.д.\n",
    "class RNNModel(nn.Module):  \n",
    "    #размерность входного вектора, сколько нейронов в скрытом состоянии,колво слоев lstm,\n",
    "    #рамерность выхода\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)# полносвязный слой в конце\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (h_n, c_n) = self.rnn(x)  \n",
    "        #out — выходы LSTM на каждом временном шаге;\n",
    "        #(h_n, c_n) — последние состояния LSTM (скрытое и ячейковое). \n",
    "        \n",
    "        # берём последнее скрытое состояние (many-to-one)\n",
    "        last_hidden = h_n[-1]# из всех слоёв берётся скрытое состояние последнего слоя LSTM\n",
    "        #(это представление всей последовательности)\n",
    "        out = self.fc(last_hidden)#Пропускаем это скрытое состояние через линейный слой, чтобы получить финальный выход\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09d13e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры модели \n",
    "input_dim = X.shape[2] #размерность признаков\n",
    "hidden_dim = 64 # размер скрытого состояния, Чем больше — тем выше способность модели запоминать \n",
    "#сложные зависимости, но и сложнее обучение.\n",
    "num_layers = 1 # число слоёв LSTM\n",
    "output_dim = 1  # выход - возраст\n",
    "\n",
    "model = RNNModel(input_dim, hidden_dim, num_layers, output_dim)\n",
    "criterion = nn.L1Loss()  # mae лучше когда есть выбросы\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bb7e46",
   "metadata": {},
   "source": [
    "Каждая эпоха — это один полный проход по всем обучающим данным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba2c0beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/40: 100%|██████████| 95/95 [00:00<00:00, 194.54it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40] Train Loss: 39.5918 | Val MSE: 1458.2007 | Val MAE: 35.0560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/40: 100%|██████████| 95/95 [00:00<00:00, 198.24it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/40] Train Loss: 30.9100 | Val MSE: 1016.8001 | Val MAE: 28.1982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/40: 100%|██████████| 95/95 [00:00<00:00, 209.91it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/40] Train Loss: 24.5441 | Val MSE: 706.1044 | Val MAE: 22.7445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/40: 100%|██████████| 95/95 [00:00<00:00, 193.66it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/40] Train Loss: 19.9925 | Val MSE: 505.2659 | Val MAE: 18.9194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/40: 100%|██████████| 95/95 [00:00<00:00, 180.01it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/40] Train Loss: 16.6609 | Val MSE: 373.2871 | Val MAE: 16.0593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/40: 100%|██████████| 95/95 [00:00<00:00, 198.57it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/40] Train Loss: 14.2191 | Val MSE: 294.7324 | Val MAE: 14.0393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/40: 100%|██████████| 95/95 [00:00<00:00, 200.67it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/40] Train Loss: 12.7880 | Val MSE: 255.7648 | Val MAE: 12.9390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/40: 100%|██████████| 95/95 [00:00<00:00, 200.80it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/40] Train Loss: 12.1472 | Val MSE: 239.4420 | Val MAE: 12.4261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/40: 100%|██████████| 95/95 [00:00<00:00, 200.57it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/40] Train Loss: 11.9050 | Val MSE: 233.9054 | Val MAE: 12.2386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/40: 100%|██████████| 95/95 [00:00<00:00, 212.03it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/40] Train Loss: 11.8133 | Val MSE: 231.6391 | Val MAE: 12.1628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/40: 100%|██████████| 95/95 [00:00<00:00, 185.91it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/40] Train Loss: 11.8065 | Val MSE: 230.7792 | Val MAE: 12.1314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/40: 100%|██████████| 95/95 [00:00<00:00, 207.57it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/40] Train Loss: 11.7987 | Val MSE: 230.4640 | Val MAE: 12.1196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/40: 100%|██████████| 95/95 [00:00<00:00, 205.26it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/40] Train Loss: 11.7719 | Val MSE: 230.3044 | Val MAE: 12.1132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/40: 100%|██████████| 95/95 [00:00<00:00, 208.98it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/40] Train Loss: 11.7959 | Val MSE: 230.3700 | Val MAE: 12.1158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/40: 100%|██████████| 95/95 [00:00<00:00, 224.75it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/40] Train Loss: 11.7868 | Val MSE: 230.2717 | Val MAE: 12.1119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/40: 100%|██████████| 95/95 [00:00<00:00, 215.02it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/40] Train Loss: 11.7850 | Val MSE: 230.2628 | Val MAE: 12.1115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/40: 100%|██████████| 95/95 [00:00<00:00, 215.02it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/40] Train Loss: 11.7809 | Val MSE: 230.2088 | Val MAE: 12.1092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/40: 100%|██████████| 95/95 [00:00<00:00, 209.09it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/40] Train Loss: 11.7992 | Val MSE: 230.1480 | Val MAE: 12.1065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/40: 100%|██████████| 95/95 [00:00<00:00, 191.37it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/40] Train Loss: 11.8093 | Val MSE: 230.2851 | Val MAE: 12.1124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/40: 100%|██████████| 95/95 [00:00<00:00, 202.24it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/40] Train Loss: 11.7853 | Val MSE: 230.2149 | Val MAE: 12.1094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/40: 100%|██████████| 95/95 [00:00<00:00, 192.97it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/40] Train Loss: 11.7992 | Val MSE: 230.1857 | Val MAE: 12.1082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/40: 100%|██████████| 95/95 [00:00<00:00, 206.25it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/40] Train Loss: 11.8089 | Val MSE: 230.3460 | Val MAE: 12.1149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/40: 100%|██████████| 95/95 [00:00<00:00, 211.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/40] Train Loss: 11.7964 | Val MSE: 230.3345 | Val MAE: 12.1144\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 40\n",
    "best_val_loss = float('inf') # начальное значение для лучшей валидационной потери\n",
    "patience = 5  # количество эпох для early stopping\n",
    "patience_counter = 0 # \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Обучение\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        optimizer.zero_grad()#обнуляем старые градиенты (иначе они будут суммироваться).\n",
    "        y_pred = model(X_batch).squeeze()#.squeeze() убирает лишние размерности\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()#вычисляем градиенты (все производные) для параметров модели\n",
    "        optimizer.step()#обновляем веса модели, используя вычисленные градиенты.\n",
    "        train_loss += loss.item()#сохраняем значение ошибки для статистики.\n",
    "    train_loss = train_loss/len(train_loader) # средняя ошибка по всем батчам\n",
    "    \n",
    "    # Валидация\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_preds = []\n",
    "    val_targets = []\n",
    "    with torch.no_grad(): # это контекстный менеджер, который отключает подсчёт градиентов\n",
    "        for X_batch, y_batch in val_loader: # модель перестаёт «учиться» и просто делает прогноз. для ускорения вычислений\n",
    "            y_pred = model(X_batch).squeeze()\n",
    "            val_loss += criterion(y_pred, y_batch).item() # накапливаем mseloss\n",
    "            # собираем для метрик mse и mae (переводим в numpy)\n",
    "            val_preds.append(y_pred.cpu().numpy())\n",
    "            val_targets.append(y_batch.cpu().numpy())\n",
    "    \n",
    "    val_loss = val_loss/len(val_loader)\n",
    "    # склеиваем батчи в один массив\n",
    "    val_preds = np.concatenate(val_preds, axis=0)\n",
    "    val_targets = np.concatenate(val_targets, axis=0)\n",
    "\n",
    "    val_mse = mean_squared_error(val_targets, val_preds)\n",
    "    val_mae = mean_absolute_error(val_targets, val_preds)\n",
    "        \n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "        f\"Train Loss: {train_loss:.4f} | \"\n",
    "        f\"Val MSE: {val_mse:.4f} | \"\n",
    "        f\"Val MAE: {val_mae:.4f}\"\n",
    "        )\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        # Сохранение лучшей модели\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f32405",
   "metadata": {},
   "source": [
    "Оценка на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4074d98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 12.5393 Test MSE: 239.2224 Test MAE: 12.5884\n"
     ]
    }
   ],
   "source": [
    "# === Оценка на тестовой выборке ===\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))# загрузим лучшую модель\n",
    "model.eval()\n",
    "\n",
    "test_preds = []\n",
    "test_targets = []\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        y_pred = model(X_batch).squeeze()\n",
    "        test_loss += criterion(y_pred, y_batch).item()\n",
    "        test_preds.append(y_pred.cpu().numpy())\n",
    "        test_targets.append(y_batch.cpu().numpy())\n",
    "\n",
    "test_loss = test_loss / len(test_loader)\n",
    "test_preds = np.concatenate(test_preds, axis=0)\n",
    "test_targets = np.concatenate(test_targets, axis=0)\n",
    "\n",
    "test_mse = mean_squared_error(test_targets, test_preds)\n",
    "test_mae = mean_absolute_error(test_targets, test_preds)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f} Test MSE: {test_mse:.4f} Test MAE: {test_mae:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
